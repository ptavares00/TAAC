import json
import torch
import os
import glob
from torch.utils.data import Dataset
from transformers import DistilBertTokenizerFast

# GENERATED BY CHATGPT - JUST A BASE TO START WITH
# THIS TUTORIAL IS VERY USEFUL - https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb#scrollTo=FiKd-zGz-iXP
# THE TOKENIZER SHOULD BE THE ONE FROM THE DISTILBERT MODEL

class ArtificialDataset(Dataset):
    def __init__(self, data_path):
        # Load the data
        # Use glob to get all .json files in the data_path
        self.json_files = glob.glob(os.path.join(data_path, "*.json"))

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        with open(self.json_files[idx], 'r') as file:
            json_file = json.load(file)
        
        return json_file
    

    def __len__(self) -> int:
        """
        Returns the number of JSON files in the dataset.
        """
        return len(self.json_files)

if __name__ == "__main__":
    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
    dataset = ArtificialDataset(data_path="/home/paulo-bessa/Downloads")
    #tokenized_dataset=prepare_dataset_for_training(dataset=dataset,tokenizer=tokenizer)
    from IPython import embed; embed()


